上下左右
远近
并拢张开
弯曲伸直

随机梯度下降（SGD）、⾃适应矩估计（Adam）、动量优化（Momentum）等


****信用评分模型：
贝叶斯优化算法
正则化的范围 特征权重的范围

特征敏感性分析

模型调整频率：
周期性调整/每季度
实时调整/每天

性能的影响：
1.特征选择：相关性强的
2.模型：适当增加复杂度
3.超参数：交叉验证/网格搜索/贝叶斯搜索到最好的
4.样本不平衡处理
5.归一化：标准，鲁棒归一化，minmax
评估指标

业务变化：
实时监控/增量更新/自适应学习率

---
***欺诈检测模型：

逻辑回归模型计算快但是非线性表现不佳，会受到特征相关性影响，可作为初步建模工具
SVM可以处理非线性但对大规模数据和高维特征要求高
决策树也可以处理非线性+可解释性好但是容易过拟合
随机森林集成学习克服了决策树过拟合可以用于大规模数据集

特征选择：
卡方验证/L1正则化
改善模型性能，增加可解释性，减少模型所需信息量

样本不均衡：
过采样/欠采样/权重调整

过拟合：正则化/交叉验证/特征选择/减少模型复杂度
欠拟合：增加特征维度/增加数据量/增加模型复杂度

特征工程：
预处理：清洗平衡归一化
选择：方差阈值、相关性、重要性
转换：热编码、特征组合、特征降维

时序分析：
滑动窗口、趋势分析、周期性

交叉验证超参数调优：
K取值/超参数搜索/模型选择


异常检测挑战：
数据量大，异常数据少，数据高维特征
解决：并行计算，特征筛选，重采样

深度学习欺诈检测大规模数据集：
并行计算/分布式架构/优化算法/模型压缩

---
***模型评估检测：

模型评价指标：
精确率、召回率、F1、AUC、ROC、PR

模型评估：
不同的模型+超参数（如随机森林、GBDT、XGBoost 等）

数据缺失值处理：
删掉/插值（均值，中位数，众数）/回归预测填充

评估模型的稳定性：
交叉验证/加噪声/性能检测/灵敏度/异常值检测/多模型集成

⾮线性关系的特征：
多项式/卷积核升维特征提取/使用非线性的模型/聚类中心

模型泛化能力表现：
风险预测的准确性/对新数据的适应能力/模型稳定性

Bagging：高方差，强分类器
boosting：低偏差，弱分类器

集成学习过拟合：
正则化、交叉验证、早停

新业务平稳运行：
灰度测试、回滚机制、实时监测

模型A/B测试：
平行测试、序列测试、交叉测试、用户分层

不平衡数据集缺失值处理：
过拟合欠拟合、重要性加权、集成学习

高斯分布适⽤于⼤规模数据集的异常值检测算法
无论原始数据的分布是什么样子的，只要你抽取足够多的样本，这些样本的平均值的分布都会趋近于高斯分布、仅需计算两个值：μ 和 σ

鲁棒的模型（如树模型）来减少异常值的影响

⾃编码器：
无监督、沙漏状态、在高维数据里可能维度灾难、数据不足会过拟合

L1：
产生稀疏性、减少过拟合、特征筛选。不适用于高度相关的特征、合适的参数调节

--------------------------------
***机器学习算法应⽤：

数据降维:
⾃编码器

孤立森林：
适合大规模数据集，对高维度特征不敏感，具有较高的可扩展性

数据增强：
平移、旋转、缩放、翻转、裁剪、噪声、对比度、亮度、遮盖

⾏为分析和预测建模：
智能交通比如预测高峰期/金融风控模型

随机森林、XGBoost等算法本⾝具有处理数据不平衡的能⼒

--------------------------------
***可解释性：

在局部层⾯可以使⽤LIME技术来解释单个样本的风险评估原因。LIME通过样本附近假数据，用简单模型拟合，突出局部特征的贡献
在全局层⾯可以使⽤SHAP值来分析每个特征对整体风险评估的影响。SHAP计算每个特征对于预测的平均贡献

应对解释性不足：
特征分析、可视化模型输出（评估指标）、树模型